{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cybersecurity Threat Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we address the critical task of anomaly detection in network traffic using the UNSW-NB15 dataset. Network anomalies can indicate malicious activities such as cyber-attacks, making their detection vital for cybersecurity.\n",
    "\n",
    "We preprocess the data by encoding categorical variables and scaling features to normalize the dataset. To enhance model performance and reduce computational complexity, we employ feature selection using a Random Forest classifier to identify the most significant features. We implement and compare four machine learning models: Random Forest, XGBoost, LightGBM, and a Neural Network. Each model undergoes hyperparameter tuning to optimize its performance. The models are evaluated using classification metrics and ROC curves to determine their effectiveness in accurately detecting anomalies within the network traffic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# For Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# For Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "\n",
    "# For Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\n",
    "train_data = pd.read_csv('Data/UNSW_NB15_training-set.csv')\n",
    "test_data = pd.read_csv('Data/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "# Combine train and test data for consistent preprocessing\n",
    "full_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# Remove 'id' and 'attack_cat' columns if present\n",
    "full_data.drop(columns=['id', 'attack_cat'], errors='ignore', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = ['proto', 'service', 'state']\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    full_data[col] = le.fit_transform(full_data[col])\n",
    "\n",
    "# Separate the target variable 'label' from features\n",
    "labels = full_data['label']\n",
    "features = full_data.drop('label', axis=1)\n",
    "\n",
    "# Scale features using StandardScaler for normalization\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the original training set size\n",
    "train_size = train_data.shape[0]\n",
    "\n",
    "# Split features and labels back into training and test sets\n",
    "X = features_scaled[:train_size]\n",
    "X_test = features_scaled[train_size:]\n",
    "y = labels[:train_size].values\n",
    "y_test = labels[train_size:].values\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train_full, X_val, y_train_full, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Random Forest to compute feature importances\n",
    "rf_selector = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_selector.fit(X_train_full, y_train_full)\n",
    "importances = rf_selector.feature_importances_\n",
    "\n",
    "# Get indices of features sorted by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the top N features based on importance\n",
    "top_n = 40\n",
    "selected_indices = indices[:top_n]\n",
    "\n",
    "# Subset the training, validation, and test data with selected features\n",
    "X_train = X_train_full[:, selected_indices]\n",
    "X_val = X_val[:, selected_indices]\n",
    "X_test_selected = X_test[:, selected_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest Classifier...\")\n",
    "\n",
    "# Define the hyperparameter grid for RandomizedSearchCV\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 20, 30, 40],\n",
    "    'max_features': ['sqrt'],  # Use 'sqrt' to avoid deprecation warnings\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier with balanced class weights\n",
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Perform hyperparameter tuning using RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=10,\n",
    "    scoring='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=3),\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search_rf.fit(X_train, y_train_full)\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "print(\"Best parameters found for Random Forest:\", random_search_rf.best_params_)\n",
    "\n",
    "# Retrain the best model on the training data\n",
    "best_rf.fit(X_train, y_train_full)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_rf = best_rf.predict(X_val)\n",
    "print(\"\\nRandom Forest Validation Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = best_rf.predict(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining XGBoost Classifier...\")\n",
    "\n",
    "# Define the hyperparameter grid for XGBoost\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 10],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "    'scale_pos_weight': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_classifier = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning using RandomizedSearchCV\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb_classifier,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=10,\n",
    "    scoring='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=3),\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search_xgb.fit(X_train, y_train_full)\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "print(\"Best parameters found for XGBoost:\", random_search_xgb.best_params_)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_xgb = best_xgb.predict(X_val)\n",
    "print(\"\\nXGBoost Validation Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = best_xgb.predict(X_test_selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining LightGBM Classifier...\")\n",
    "\n",
    "# Define the hyperparameter grid for LightGBM\n",
    "param_dist_lgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'num_leaves': [31, 50],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Initialize the LightGBM Classifier\n",
    "lgb_classifier = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning using RandomizedSearchCV\n",
    "random_search_lgb = RandomizedSearchCV(\n",
    "    estimator=lgb_classifier,\n",
    "    param_distributions=param_dist_lgb,\n",
    "    n_iter=10,\n",
    "    scoring='f1_macro',\n",
    "    cv=StratifiedKFold(n_splits=3),\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search_lgb.fit(X_train, y_train_full)\n",
    "best_lgb = random_search_lgb.best_estimator_\n",
    "print(\"Best parameters found for LightGBM:\", random_search_lgb.best_params_)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_lgb = best_lgb.predict(X_val)\n",
    "print(\"\\nLightGBM Validation Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_lgb))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lgb = best_lgb.predict(X_test_selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Neural Network Classifier...\")\n",
    "\n",
    "# Initialize the neural network model\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model_nn.add(Dropout(0.5))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dropout(0.5))\n",
    "model_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the neural network\n",
    "model_nn.fit(X_train, y_train_full, epochs=10, batch_size=256, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_nn_prob = model_nn.predict(X_val)\n",
    "# Convert probabilities to binary predictions\n",
    "y_val_pred_nn = (y_val_pred_nn_prob > 0.5).astype(int).reshape(-1)\n",
    "print(\"\\nNeural Network Validation Performance:\")\n",
    "print(classification_report(y_val, y_val_pred_nn))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nn_prob = model_nn.predict(X_test_selected)\n",
    "y_pred_nn = (y_pred_nn_prob > 0.5).astype(int).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return fpr, tpr, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plot for ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Evaluate Random Forest\n",
    "fpr_rf, tpr_rf, roc_auc_rf = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest ROC (area = %0.2f)' % roc_auc_rf)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "fpr_xgb, tpr_xgb, roc_auc_xgb = evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGBoost ROC (area = %0.2f)' % roc_auc_xgb)\n",
    "\n",
    "# Evaluate LightGBM\n",
    "fpr_lgb, tpr_lgb, roc_auc_lgb = evaluate_model(y_test, y_pred_lgb, \"LightGBM\")\n",
    "plt.plot(fpr_lgb, tpr_lgb, label='LightGBM ROC (area = %0.2f)' % roc_auc_lgb)\n",
    "\n",
    "# Evaluate Neural Network\n",
    "fpr_nn, tpr_nn, roc_auc_nn = evaluate_model(y_test, y_pred_nn, \"Neural Network\")\n",
    "plt.plot(fpr_nn, tpr_nn, label='Neural Network ROC (area = %0.2f)' % roc_auc_nn)\n",
    "\n",
    "# Finalize ROC curve plot\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*High Recall for Anomalies*\n",
    "\\\n",
    "All models demonstrated a high recall for detecting anomalies (Class 1), with values ranging from 0.98 to 0.99. This indicates that the models are proficient at identifying anomalous network traffic, which is crucial for cybersecurity applications where missing an anomaly could have severe consequences.\n",
    "\\\n",
    "\\\n",
    "*Lower Recall for Normal Traffic*\n",
    "\\\n",
    "The recall for normal traffic (Class 0) was significantly lower across all models, particularly for the Neural Network and XGBoost classifiers. This suggests that the models are misclassifying a substantial portion of normal traffic as anomalies, leading to a higher false-positive rate.\n",
    "\\\n",
    "\\\n",
    "*Random Forest and LightGBM Performance*\n",
    "\\\n",
    "The Random Forest and LightGBM classifiers achieved a better balance between precision and recall for normal traffic compared to the other models. With recalls of 0.76 and 0.74, respectively, they misclassified fewer normal instances as anomalies while maintaining high anomaly detection rates.\n",
    "\\\n",
    "\\\n",
    "*Overall Accuracy and F1-Scores*\n",
    "\\\n",
    "The overall accuracy of the models ranged from 0.83 to 0.88, with the Random Forest classifier achieving the highest accuracy. The F1-scores for anomalies were consistently high, reflecting the models' effectiveness in correctly identifying anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
